# üî¢ Classification MNIST - Application Compl√®te

Une application de reconnaissance de chiffres manuscrits avec interface web interactive et API REST.

## üìä Architecture G√©n√©rale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    HTTP     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Import    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  ‚îÇ    Backend      ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí   ‚îÇ     Mod√®le      ‚îÇ
‚îÇ   Streamlit     ‚îÇ             ‚îÇ    FastAPI      ‚îÇ              ‚îÇ     PyTorch     ‚îÇ
‚îÇ   (Port 8501)   ‚îÇ             ‚îÇ   (Port 8000)   ‚îÇ              ‚îÇ   (ConvNet)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                               ‚îÇ                               ‚îÇ
        ‚îÇ                               ‚îÇ                               ‚îÇ
   Canvas Drawing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Prediction API ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Neural Network
   User Interface                  REST Endpoints                  MNIST Classifier
```

## üß† 1. Mod√®le Neural Network (`src/model/main.py`)

### **R√¥le**
Ce fichier contient l'entra√Ænement du r√©seau de neurones convolutionnel pour la classification MNIST.

### **Architecture ConvNet**
```python
class ConvNet(nn.Module):
    def __init__(self, input_size, n_kernels, output_size):
        self.net = nn.Sequential(
            # Couche 1: Conv2D (1‚Üí6 canaux) + ReLU + MaxPool
            nn.Conv2d(in_channels=1, out_channels=n_kernels, kernel_size=5),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),
            
            # Couche 2: Conv2D (6‚Üí6 canaux) + ReLU + MaxPool  
            nn.Conv2d(in_channels=n_kernels, out_channels=n_kernels, kernel_size=5),
            nn.ReLU(), 
            nn.MaxPool2d(kernel_size=2),
            
            # Aplatissement et couches fully connected
            nn.Flatten(),
            nn.Linear(in_features=n_kernels * 4 * 4, out_features=50),
            nn.ReLU(),
            nn.Linear(in_features=50, out_features=output_size)  # 10 classes
        )
```

### **Processus d'Entra√Ænement**
1. **Chargement donn√©es** : MNIST via torchvision
2. **Normalisation** : Moyenne=0.1307, Std=0.3081 (standard MNIST)
3. **Permutation pixels** : `perm = torch.randperm(784)` pour augmenter la difficult√©
4. **Optimisation** : AdamW optimizer
5. **Sauvegarde** : Mod√®le + permutation + m√©tadonn√©es dans `models/convnet.pt`

### **Particularit√© : Permutation des Pixels**
```python
# Pendant l'entra√Ænement
data_flattened = data.view(batch_size, -1)     # 28x28 ‚Üí 784 pixels
data_permuted = data_flattened[:, perm]        # R√©organiser les pixels
data_reshaped = data_permuted.view(batch_size, 1, 28, 28)  # Retour 28x28
```

**Pourquoi ?** Cela force le mod√®le √† apprendre des patterns plus robustes, pas juste la position des pixels.

### **Format de Sauvegarde**
```python
model_data = {
    'model_state_dict': convnet.state_dict(),  # Poids du r√©seau
    'permutation': perm,                       # Permutation utilis√©e
    'n_kernels': 6,                           # Architecture
    'input_size': 1,
    'output_size': 10
}
```

---

## üöÄ 2. API Backend (`src/app/main.py`)

### **R√¥le**
API REST FastAPI qui expose le mod√®le entra√Æn√© pour faire des pr√©dictions.

### **Endpoints**
```
GET  /              ‚Üí Informations sur l'API
POST /api/v1/predict ‚Üí Pr√©diction d'image (upload fichier)
GET  /docs          ‚Üí Documentation Swagger automatique
```

### **Chargement du Mod√®le**
```python
# Chargement intelligent avec r√©trocompatibilit√©
checkpoint = torch.load(model_path, map_location=device)

if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
    # Nouveau format (avec permutation)
    permutation = checkpoint.get('permutation', torch.randperm(784))
    model.load_state_dict(checkpoint['model_state_dict'])
else:
    # Ancien format (sans permutation) 
    model.load_state_dict(checkpoint)
    permutation = torch.randperm(784)  # Al√©atoire !
```

### **Pipeline de Pr√©diction**
```python
def preprocess_image(image_bytes) -> torch.Tensor:
    # 1. D√©codage image
    image = Image.open(io.BytesIO(image_bytes))
    
    # 2. Conversion niveaux de gris + redimensionnement 28x28
    image = image.convert('L').resize((28, 28))
    
    # 3. Normalisation [0,255] ‚Üí [0,1]
    image_array = np.array(image, dtype=np.float32) / 255.0
    
    # 4. Inversion couleurs si n√©cessaire (MNIST = fond noir)
    if image_array.mean() > 0.5:
        image_array = 1.0 - image_array
    
    # 5. Normalisation MNIST (Œº=0.1307, œÉ=0.3081)
    image_array = (image_array - 0.1307) / 0.3081
    
    # 6. Application de la M√äME permutation que l'entra√Ænement
    image_tensor = torch.from_numpy(image_array.flatten())
    image_permuted = image_tensor[permutation]  # CRUCIAL !
    image_reshaped = image_permuted.view(1, 28, 28)
    
    return image_reshaped
```

### **S√©curit√©**
- **Validation mod√®le** : Refuse de d√©marrer sans mod√®le entra√Æn√©
- **Gestion erreurs** : Try/catch pour les uploads malform√©s
- **Types stricts** : FastAPI avec validation automatique

---

## üé® 3. Interface Frontend (`src/app/streamlit_app.py`)

### **R√¥le** 
Interface web interactive permettant de dessiner des chiffres et obtenir des pr√©dictions en temps r√©el.

### **Composants Principaux**

#### **Canvas de Dessin**
```python
canvas_result = st_canvas(
    fill_color="rgba(255, 255, 255, 0.0)",  # Transparent
    stroke_width=20,                        # Trait √©pais
    stroke_color="#000000",                 # Noir
    background_color="#FFFFFF",             # Fond blanc
    width=280, height=280,                  # Grande taille
    drawing_mode="freedraw",
    key="canvas"
)
```

#### **Preprocessing en Temps R√©el**
```python
# Conversion automatique RGBA ‚Üí Grayscale ‚Üí 28x28
img = Image.fromarray(canvas_result.image_data.astype('uint8'), 'RGBA')
img_gray = img.convert('L')
img_resized = img_gray.resize((28, 28), Image.LANCZOS)
```

#### **Communication avec l'API**
```python
# Configuration flexible (Docker-ready)
API_URL = os.getenv("API_URL", "http://localhost:8000/api/v1/predict")

# Upload et pr√©diction
files = {"file": img_bytes}
response = requests.post(API_URL, files=files, timeout=10)
```

### **Visualisations**
- **M√©trique principale** : Chiffre pr√©dit + confiance
- **Graphique barres** : Probabilit√©s des 10 classes
- **D√©tails expandable** : Probabilit√©s exactes avec barres de progression
- **Monitoring API** : Statut de connexion en temps r√©el

### **Gestion d'Erreurs**
```python
try:
    response = requests.post(API_URL, files=files, timeout=10)
    # Traitement r√©ussi
except requests.exceptions.ConnectionError:
    st.error("‚ùå Impossible de se connecter √† l'API")
except Exception as e:
    st.error(f"‚ùå Erreur: {str(e)}")
```

---

## üê≥ 4. Dockerisation

### **Architecture Multi-Conteneurs**
```yaml
services:
  backend:      # API FastAPI
    ports: ["8000:8000"]
    volumes: ["./models:/app/models"]
    
  frontend:     # Interface Streamlit  
    ports: ["8501:8501"]
    environment: ["API_URL=http://backend:8000/api/v1/predict"]
    depends_on: [backend]
```

### **Backend Dockerfile**
```dockerfile
FROM python:3.11-slim
WORKDIR /app

# Installation d√©pendances
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Code source
COPY src/ ./src/

# Mod√®les (avec fallback si vide)
RUN mkdir -p ./models
COPY models/ ./models/

# Configuration Python
ENV PYTHONPATH=/app/src
ENV PYTHONUNBUFFERED=1

# Lancement
CMD ["uvicorn", "src.app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### **Frontend Dockerfile**
```dockerfile
FROM python:3.11-slim
WORKDIR /app

# Installation + app Streamlit
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY src/app/streamlit_app.py ./

# Configuration Streamlit
ENV STREAMLIT_SERVER_PORT=8501
ENV STREAMLIT_SERVER_ADDRESS=0.0.0.0

# Lancement
CMD ["streamlit", "run", "streamlit_app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

---

## üîÑ Flux de Donn√©es Complet

```
1. [Utilisateur] Dessine un chiffre dans le canvas Streamlit
                 ‚Üì
2. [Frontend] Convertit le dessin en image 28x28 pixels
                 ‚Üì
3. [Frontend] Envoie POST /api/v1/predict avec l'image
                 ‚Üì
4. [Backend] Re√ßoit l'image et applique le preprocessing :
   ‚Ä¢ Normalisation MNIST
   ‚Ä¢ Application de la permutation sauvegard√©e
                 ‚Üì
5. [Backend] Passe l'image dans le mod√®le ConvNet
                 ‚Üì
6. [Backend] Retourne JSON avec pr√©diction + probabilit√©s
                 ‚Üì
7. [Frontend] Affiche r√©sultats avec visualisations
```

---

## üöÄ Utilisation

### **Entra√Ænement**
```bash
python train_model.py                    # 10 epochs, sauvegarde dans models/
```

### **Mode D√©veloppement**
```bash
# Terminal 1 - API
uvicorn src.app.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2 - Frontend  
streamlit run src/app/streamlit_app.py
```

### **Mode Production (Docker)**
```bash
docker compose up --build              # Build + lancement
# Frontend: http://localhost:8501
# Backend:  http://localhost:8000
```

---

## ü§ñ CI/CD avec GitHub Actions

### **Pipeline Automatique**

Le workflow `.github/workflows/docker.yml` automatise compl√®tement le processus :

```yaml
on:
  push:
    branches: [ main, develop ]    # Auto-build sur push
    tags: [ 'v*' ]                # Production sur tags
  pull_request:
    branches: [ main ]            # Tests sur PR
```

### **Strat√©gie de D√©ploiement**

#### üü° **Staging** (branche `develop`)
- **D√©clencheur** : Push sur `develop`
- **Images** : `ghcr.io/owner/repo/mnist-{frontend,backend}:develop`
- **URL** : `http://localhost:8511` (frontend), `http://localhost:8010` (backend)

#### üü¢ **Production** (tags `v*`)
- **D√©clencheur** : Tags de version (ex: `v1.0.0`)
- **Images** : `ghcr.io/owner/repo/mnist-{frontend,backend}:v1.0.0`
- **URL** : `http://localhost:8501` (frontend), `http://localhost:8000` (backend)
- **Release** : Cr√©ation automatique de GitHub Release

### **Registry d'Images**

Les images sont automatiquement publi√©es sur **GitHub Container Registry** :

```bash
# Images disponibles
docker pull ghcr.io/owner/repo/mnist-frontend:latest
docker pull ghcr.io/owner/repo/mnist-backend:latest
docker pull ghcr.io/owner/repo/mnist-frontend:v1.0.0
docker pull ghcr.io/owner/repo/mnist-backend:v1.0.0
```

### **D√©ploiement Manuel**

#### **Script de D√©ploiement**
```bash
# Staging
./deploy.sh staging develop

# Production  
./deploy.sh production v1.0.0
./deploy.sh production latest
```

#### **Docker Compose Direct**
```bash
# Staging
export GITHUB_REPOSITORY="owner/repo"
export VERSION="develop"
docker-compose -f docker-compose.staging.yml up -d

# Production
export GITHUB_REPOSITORY="owner/repo" 
export VERSION="v1.0.0"
docker-compose -f docker-compose.prod.yml up -d
```

### **S√©curit√© & Monitoring**

#### **Scan de Vuln√©rabilit√©s**
- **Trivy** scan automatique des images
- **SARIF** upload vers GitHub Security
- **Bloquant** pour les d√©ploiements production

#### **Health Checks**
```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8000/"]
  interval: 30s
  timeout: 10s
  retries: 3
```

#### **Utilisateurs Non-Root**
```dockerfile
RUN groupadd -r appuser && useradd -r -g appuser appuser
USER appuser
```

### **Workflow Complet**

```mermaid
graph TD
    A[Push Code] --> B{Branch?}
    B -->|develop| C[Build Images]
    B -->|main| D[Build + Test]
    B -->|v*| E[Build + Prod Deploy]
    
    C --> F[Deploy Staging]
    D --> G[Run Tests]
    E --> H[Security Scan]
    
    F --> I[Staging Available]
    G --> J[PR Validated]
    H --> K[Production Deploy]
    
    K --> L[GitHub Release]
    K --> M[Production Available]
```

### **Variables d'Environnement**

Pour configurer votre d√©ploiement, cr√©ez ces secrets GitHub :

```bash
# GitHub Repository Settings > Secrets
REGISTRY_USERNAME=your-github-username
REGISTRY_PASSWORD=your-github-token  # Avec permissions packages:write

# Pour d√©ploiements automatiques (optionnel)
DEPLOY_SSH_KEY=your-production-ssh-key
PRODUCTION_HOST=your-server.com
STAGING_HOST=staging.your-server.com
```

---

## üîç Points Techniques Avanc√©s

### **Permutation des Pixels**
- **Probl√®me** : Sans permutation, le mod√®le apprend juste la position des pixels
- **Solution** : M√©langer l'ordre des pixels force √† apprendre des features plus robustes
- **Impl√©mentation** : `perm = torch.randperm(784)` appliqu√© de mani√®re identique train/test/prod

### **Normalisation Multi-√âtapes**
1. **[0,255] ‚Üí [0,1]** : Division par 255
2. **Inversion couleurs** : `1.0 - image` si fond blanc d√©tect√©
3. **Standardisation MNIST** : `(x - 0.1307) / 0.3081`

### **Gestion √âtats**
- **Mod√®le** : Charg√© une fois au d√©marrage de l'API
- **Permutation** : Sauvegard√©e avec le mod√®le pour coh√©rence
- **Session** : Streamlit maintient l'√©tat du canvas entre interactions

### **Robustesse**
- **API** : Refuse de d√©marrer sans mod√®le valide
- **Frontend** : D√©tection automatique de l'√©tat de l'API
- **Docker** : Healthchecks et restart policies
